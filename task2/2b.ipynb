{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Skip-gram model\n",
    "skipgram_model = Word2Vec.load(\"../word2vec_skipgram_window2.model\")\n",
    "\n",
    "# Load Skip-gram Negative Sampling model\n",
    "skipgram_neg_model = Word2Vec.load(\"../word2vec_ns_window2.model\")\n",
    "\n",
    "# Load the GloVe embeddings as a NumPy array\n",
    "glove_embeddings = np.load(\"../glove_embeddings.npy\")\n",
    "\n",
    "# Load the GloVe embeddings as a Gensim KeyedVectors model\n",
    "glove_gensim_model = KeyedVectors.load(\"../glove_gensim.kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_test(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    syntactic_questions = []\n",
    "    semantic_questions = []\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        if \":\" in line:  # New section\n",
    "            current_section = \"semantic\" if \"semantic\" in line.lower() else \"syntactic\"\n",
    "        elif current_section == \"syntactic\":\n",
    "            syntactic_questions.append(line.strip().split())\n",
    "        elif current_section == \"semantic\":\n",
    "            semantic_questions.append(line.strip().split())\n",
    "\n",
    "    return syntactic_questions, semantic_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word-test data\n",
    "syntactic_questions, semantic_questions = load_word_test(\"word-test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy evaluation function\n",
    "def evaluate_accuracy(model, questions):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for q in questions:\n",
    "        try:\n",
    "            predicted = model.most_similar(positive=[q[1], q[2]], negative=[q[0]], topn=1)[0][0]\n",
    "            if predicted == q[3]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        except KeyError:\n",
    "            # Skip if a word is not in vocabulary\n",
    "            continue\n",
    "\n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "# GloVe-specific accuracy evaluation (NumPy)\n",
    "# Updated GloVe-specific accuracy evaluation (NumPy)\n",
    "def evaluate_glove_accuracy(glove_embeddings, vocab, questions):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for q in questions:\n",
    "        try:\n",
    "            # Get vector representations using the vocabulary mapping\n",
    "            vec = (\n",
    "                glove_embeddings[vocab[q[1]]] +\n",
    "                glove_embeddings[vocab[q[2]]] -\n",
    "                glove_embeddings[vocab[q[0]]]\n",
    "            )\n",
    "            # Find the word with the highest similarity to the vector\n",
    "            predicted = max(vocab.keys(), key=lambda word: np.dot(vec, glove_embeddings[vocab[word]]))\n",
    "            if predicted == q[3]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        except KeyError:\n",
    "            # Skip if any word in the analogy is not in vocabulary\n",
    "            continue\n",
    "\n",
    "    return correct / total if total > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path):\n",
    "    with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        vocab = {}\n",
    "        vectors = []\n",
    "        for idx, line in enumerate(f):\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array(parts[1:], dtype=np.float32)\n",
    "            vocab[word] = idx\n",
    "            vectors.append(vector)\n",
    "        glove_embeddings = np.array(vectors)\n",
    "    return glove_embeddings, vocab\n",
    "\n",
    "# Load GloVe embeddings and create word-to-index mapping\n",
    "glove_embeddings, glove_vocab = load_glove_embeddings(\"../glove.6B/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Syntactic and Semantic Accuracy\n",
    "# For Skip-gram models\n",
    "syntactic_accuracy_skipgram = evaluate_accuracy(skipgram_model.wv, syntactic_questions)\n",
    "semantic_accuracy_skipgram = evaluate_accuracy(skipgram_model.wv, semantic_questions)\n",
    "\n",
    "syntactic_accuracy_skipgram_neg = evaluate_accuracy(skipgram_neg_model.wv, syntactic_questions)\n",
    "semantic_accuracy_skipgram_neg = evaluate_accuracy(skipgram_neg_model.wv, semantic_questions)\n",
    "\n",
    "# For GloVe (NumPy embeddings)\n",
    "syntactic_accuracy_glove = evaluate_glove_accuracy(glove_embeddings, glove_vocab, syntactic_questions)\n",
    "semantic_accuracy_glove = evaluate_glove_accuracy(glove_embeddings, glove_vocab, semantic_questions)\n",
    "\n",
    "# For GloVe (Gensim-compatible)\n",
    "syntactic_accuracy_glove_gensim = evaluate_accuracy(glove_gensim_model, syntactic_questions)\n",
    "semantic_accuracy_glove_gensim = evaluate_accuracy(glove_gensim_model, semantic_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "print(\"Skip-gram - Syntactic Accuracy:\", syntactic_accuracy_skipgram)\n",
    "print(\"Skip-gram - Semantic Accuracy:\", semantic_accuracy_skipgram)\n",
    "print(\"Skip-gram (NEG) - Syntactic Accuracy:\", syntactic_accuracy_skipgram_neg)\n",
    "print(\"Skip-gram (NEG) - Semantic Accuracy:\", semantic_accuracy_skipgram_neg)\n",
    "print(\"GloVe - Syntactic Accuracy:\", syntactic_accuracy_glove)\n",
    "print(\"GloVe - Semantic Accuracy:\", semantic_accuracy_glove)\n",
    "print(\"GloVe (Gensim) - Syntactic Accuracy:\", syntactic_accuracy_glove_gensim)\n",
    "print(\"GloVe (Gensim) - Semantic Accuracy:\", semantic_accuracy_glove_gensim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
